{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1182., 1053., 1002., 2220.]),\n",
       " array([0., 1., 2., 3., 4.]),\n",
       " <BarContainer object of 4 artists>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beesDB = pd.read_csv('./level_1/training_data.csv', header = None)\n",
    "npBest = beesDB.values\n",
    "# pandas to np array\n",
    "\n",
    "plt.hist(npBest[:,1], bins=[0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5275, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter pandas where first column doesn't have 30 characters\n",
    "beesFiltered = beesDB[beesDB.iloc[:,0].str.len() == 30]\n",
    "beesFiltered.head()\n",
    "beesFiltered.shape\n",
    "# plt.hist(beesFiltered.iloc[:,1], bins=[0,1,2,3,4,5])\n",
    "# beesDB.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network to classify bees with sklearn\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertStringToNpIntArray(string):\n",
    "    return np.array([ord(x) - ord('a') for x in string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "beesEncoded = beesFiltered.iloc[:,0].apply(convertStringToNpIntArray)\n",
    "# beesEncoded = beesFiltered.iloc[:,0]\n",
    "# beesEncoded.insert(0, '1', beesFiltered.iloc[:,1])\n",
    "beesEncoded = beesEncoded.to_frame()\n",
    "beesEncoded.insert(1, '1', beesFiltered.iloc[:,1])\n",
    "\n",
    "X_train = np.stack(beesEncoded.iloc[:,0].values)\n",
    "y_train = np.stack(beesEncoded.iloc[:,1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.0005, hidden_layer_sizes=(50, 50, 50, 50, 50, 50),\n",
       "              max_iter=50000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.0005, hidden_layer_sizes=(50, 50, 50, 50, 50, 50),\n",
       "              max_iter=50000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.0005, hidden_layer_sizes=(50, 50, 50, 50, 50, 50),\n",
       "              max_iter=50000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the neural network with 5 output neurons using scikit-learn\n",
    "mlp = MLPClassifier(alpha = 5e-4,hidden_layer_sizes=(50,50,50,50,50,50), max_iter=50000)\n",
    "mlp.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadTest(path: str):\n",
    "    testData = pd.read_csv(path, header = None)\n",
    "    testData = testData.iloc[:,0].apply(convertStringToNpIntArray)\n",
    "    testData = np.stack(testData.values)\n",
    "    return testData\n",
    "def writeResult(path: str, result):\n",
    "    with open(path, 'w') as f:\n",
    "        for item in result:\n",
    "            f.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = loadTest('./level_6/imbalanced_test_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 19:59:19.412792: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-11 19:59:23.517085: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-11 19:59:23.517147: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-11 19:59:23.868038: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-11 19:59:34.488563: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-11 19:59:34.489120: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-11 19:59:34.489139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "165/165 [==============================] - 1s 2ms/step - loss: 1.6209 - accuracy: 0.2123\n",
      "Epoch 2/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.6044 - accuracy: 0.2298\n",
      "Epoch 3/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.6033 - accuracy: 0.2375\n",
      "Epoch 4/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.5954 - accuracy: 0.2529\n",
      "Epoch 5/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.5843 - accuracy: 0.2713\n",
      "Epoch 6/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.5716 - accuracy: 0.2842\n",
      "Epoch 7/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.5573 - accuracy: 0.2891\n",
      "Epoch 8/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.5385 - accuracy: 0.3014\n",
      "Epoch 9/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.5284 - accuracy: 0.3065\n",
      "Epoch 10/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.5027 - accuracy: 0.3299\n",
      "Epoch 11/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.4882 - accuracy: 0.3433\n",
      "Epoch 12/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.4665 - accuracy: 0.3490\n",
      "Epoch 13/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.4504 - accuracy: 0.3649\n",
      "Epoch 14/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.4323 - accuracy: 0.3674\n",
      "Epoch 15/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.4180 - accuracy: 0.3784\n",
      "Epoch 16/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.4043 - accuracy: 0.3888\n",
      "Epoch 17/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.3856 - accuracy: 0.3943\n",
      "Epoch 18/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.3740 - accuracy: 0.4112\n",
      "Epoch 19/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.3592 - accuracy: 0.4070\n",
      "Epoch 20/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.3359 - accuracy: 0.4218\n",
      "Epoch 21/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.3385 - accuracy: 0.4138\n",
      "Epoch 22/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.3198 - accuracy: 0.4305\n",
      "Epoch 23/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.3027 - accuracy: 0.4417\n",
      "Epoch 24/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.2912 - accuracy: 0.4447\n",
      "Epoch 25/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.2805 - accuracy: 0.4531\n",
      "Epoch 26/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.2617 - accuracy: 0.4603\n",
      "Epoch 27/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.2506 - accuracy: 0.4688\n",
      "Epoch 28/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.2319 - accuracy: 0.4673\n",
      "Epoch 29/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.2218 - accuracy: 0.4747\n",
      "Epoch 30/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.2047 - accuracy: 0.4827\n",
      "Epoch 31/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.2034 - accuracy: 0.4819\n",
      "Epoch 32/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.1898 - accuracy: 0.4944\n",
      "Epoch 33/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.1769 - accuracy: 0.4942\n",
      "Epoch 34/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.1670 - accuracy: 0.5043\n",
      "Epoch 35/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.1574 - accuracy: 0.5027\n",
      "Epoch 36/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.1380 - accuracy: 0.5122\n",
      "Epoch 37/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.1340 - accuracy: 0.5109\n",
      "Epoch 38/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.1230 - accuracy: 0.5170\n",
      "Epoch 39/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.1169 - accuracy: 0.5257\n",
      "Epoch 40/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.5312\n",
      "Epoch 41/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.1069 - accuracy: 0.5255\n",
      "Epoch 42/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0893 - accuracy: 0.5390\n",
      "Epoch 43/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0842 - accuracy: 0.5342\n",
      "Epoch 44/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0645 - accuracy: 0.5467\n",
      "Epoch 45/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0523 - accuracy: 0.5515\n",
      "Epoch 46/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0547 - accuracy: 0.5503\n",
      "Epoch 47/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0502 - accuracy: 0.5579\n",
      "Epoch 48/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0397 - accuracy: 0.5619\n",
      "Epoch 49/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0181 - accuracy: 0.5754\n",
      "Epoch 50/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0251 - accuracy: 0.5697\n",
      "Epoch 51/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0215 - accuracy: 0.5640\n",
      "Epoch 52/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0193 - accuracy: 0.5708\n",
      "Epoch 53/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0109 - accuracy: 0.5801\n",
      "Epoch 54/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0084 - accuracy: 0.5759\n",
      "Epoch 55/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 1.0097 - accuracy: 0.5757\n",
      "Epoch 56/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9849 - accuracy: 0.5843\n",
      "Epoch 57/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9842 - accuracy: 0.5854\n",
      "Epoch 58/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9684 - accuracy: 0.5917\n",
      "Epoch 59/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9483 - accuracy: 0.6009\n",
      "Epoch 60/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9663 - accuracy: 0.5932\n",
      "Epoch 61/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9758 - accuracy: 0.5882\n",
      "Epoch 62/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9500 - accuracy: 0.5958\n",
      "Epoch 63/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9504 - accuracy: 0.6009\n",
      "Epoch 64/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9505 - accuracy: 0.6055\n",
      "Epoch 65/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9353 - accuracy: 0.6099\n",
      "Epoch 66/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9415 - accuracy: 0.6142\n",
      "Epoch 67/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9106 - accuracy: 0.6277\n",
      "Epoch 68/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9446 - accuracy: 0.6030\n",
      "Epoch 69/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9200 - accuracy: 0.6142\n",
      "Epoch 70/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9122 - accuracy: 0.6171\n",
      "Epoch 71/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9177 - accuracy: 0.6241\n",
      "Epoch 72/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9017 - accuracy: 0.6241\n",
      "Epoch 73/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8925 - accuracy: 0.6292\n",
      "Epoch 74/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.9018 - accuracy: 0.6281\n",
      "Epoch 75/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8959 - accuracy: 0.6260\n",
      "Epoch 76/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8886 - accuracy: 0.6362\n",
      "Epoch 77/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8913 - accuracy: 0.6343\n",
      "Epoch 78/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8835 - accuracy: 0.6364\n",
      "Epoch 79/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8693 - accuracy: 0.6419\n",
      "Epoch 80/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8759 - accuracy: 0.6370\n",
      "Epoch 81/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8846 - accuracy: 0.6353\n",
      "Epoch 82/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8656 - accuracy: 0.6427\n",
      "Epoch 83/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8753 - accuracy: 0.6408\n",
      "Epoch 84/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8474 - accuracy: 0.6457\n",
      "Epoch 85/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8330 - accuracy: 0.6499\n",
      "Epoch 86/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8451 - accuracy: 0.6523\n",
      "Epoch 87/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8464 - accuracy: 0.6480\n",
      "Epoch 88/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8511 - accuracy: 0.6478\n",
      "Epoch 89/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8371 - accuracy: 0.6500\n",
      "Epoch 90/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8323 - accuracy: 0.6622\n",
      "Epoch 91/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8356 - accuracy: 0.6571\n",
      "Epoch 92/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8164 - accuracy: 0.6658\n",
      "Epoch 93/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8344 - accuracy: 0.6573\n",
      "Epoch 94/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8113 - accuracy: 0.6796\n",
      "Epoch 95/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8331 - accuracy: 0.6540\n",
      "Epoch 96/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8175 - accuracy: 0.6686\n",
      "Epoch 97/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8293 - accuracy: 0.6590\n",
      "Epoch 98/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8003 - accuracy: 0.6773\n",
      "Epoch 99/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8185 - accuracy: 0.6652\n",
      "Epoch 100/100\n",
      "165/165 [==============================] - 0s 2ms/step - loss: 0.8326 - accuracy: 0.6614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38722ba700>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the neural network with 5 output neurons using keras\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(5, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=100)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# model.evaluate(X_train, y_train)\n",
    "beesAns4 = model.predict(testData)\n",
    "beesAns4 = np.argmax(beesAns4, axis=1)\n",
    "beesAns4\n",
    "writeResult('beesAns4', beesAns4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1: lstm 30, 2 de 50 dense, dropout 0.2, 2 dense 50, dense 5 output cu softmax - 96% fscore\n",
    "- 2: lstm 50, 2 de 50 dense, dropout 0.3, la fel - 94% fscore\n",
    "- 3: lstm 50, 2 de 50 dense, dropout 0.2, la fel - 93% fscore\n",
    "- 4: lstm 30, 2 de 50 dense, dropout 0.2, 1 dens 50, output - 86% -> nu trebuie complexitate scazuta\n",
    "- 5: lstm 30, 2 de 50 dense, dropout 0.2, 3 dense 50, output - probabil mai jos, deci nu extra dense layer\n",
    "- 6: lstm 30, 2 de 50 dense, dropout 0.15, 2 dense 50, output - probabil, mai jos, nu dropout mai mare\n",
    "- 7: lstm 30, 2 dense de 50, dropout 0.2, 2 dense de 50, dense 5 output cu softmax - (=1 config) \n",
    "- 8: 2 lstm 30, 2 dense de 50, dropout 0.2, 2 dense de 50, dense 5 output cu softmax - 97% - deci ne trebuie complexitate si mai mare\n",
    "- 9: 3 lstm 30, 2 dense de 50, dropout 0.2, 1 dense de 50, dense 5 output cu softmax - cu speranta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-11 19:59:57.573330: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (100)\n",
      "2022-11-11 19:59:57.573403: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Laptop): /proc/driver/nvidia/version does not exist\n",
      "2022-11-11 19:59:57.578244: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 16\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mSequential([\n\u001b[1;32m      3\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLSTM(\u001b[39m30\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m,\u001b[39m1\u001b[39m), return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m      4\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLSTM(\u001b[39m30\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m,\u001b[39m1\u001b[39m), return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m5\u001b[39m, activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39msoftmax)\n\u001b[1;32m     12\u001b[0m ])\n\u001b[1;32m     13\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m                 loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                 metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 16\u001b[0m model\u001b[39m.\u001b[39mfit(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# LSTM using keras\n",
    "model = keras.Sequential([\n",
    "    keras.layers.LSTM(30, input_shape=(30,1), return_sequences=True),\n",
    "    keras.layers.LSTM(30, input_shape=(30,1), return_sequences=True),\n",
    "    keras.layers.LSTM(30, input_shape=(30,1), return_sequences=True),\n",
    "    keras.layers.LSTM(30, input_shape=(30,1)),\n",
    "    \n",
    "    \n",
    "    keras.layers.Dense(50, activation=tf.nn.relu),\n",
    "    \n",
    "    keras.layers.Dense(5, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "beesAns4 = model.predict(testData)\n",
    "beesAns4 = np.argmax(beesAns4, axis=1)\n",
    "beesAns4\n",
    "writeResult('beesAns4', beesAns4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 2 3 0 0 4 1 0 2 2 0 2 1 1 1 1 3 0 2 1 4 3 1 4 4 3 1 3 0 1 4 3 0 0 2\n",
      " 1 4 4 0 2 0 4 2 4 0 0 1 0 2 2 0 0 1 3 2 3 4 0 2 4 1 0 1 2 4 0 4 2 3 1 2 2\n",
      " 2 4 4 4 1 1 1 0 3 4 0 1 2 3 0 1 2 4 3 3 1 4 0 4 0 4 1 0 4 4 1 2 0 3 1 2 2\n",
      " 4 3 1 4 0 4 4 3 1 3 0 2 4 3 0 0 3 1 2 0 1 1 1 2 3 3 4 0 1 2 3 2 2 2 2 2 4\n",
      " 3 1 0 3 1 3 3 4 0 0 1 2 1 2 0 1 0 3 1 0 1 1 1 1 4 4 3 4 1 1 2 3 1 1 4 3 1\n",
      " 2 2 4 4 1 2 0 0 3 0 1 0 0 0 1 0 2 0 0 2 4 0 4 1 1 2 2 4 1 3 0 3 1 1 2 0 1\n",
      " 3 4 0 1 4 4 2 4 4 0 0 4 2 3 4 1 0 3 1 0 3 1 4 1 0 4 1 2 4 2 0 2 1 2 2 2 3\n",
      " 3 2 1 0 0 2 1 4 3 3 2 2 4 1 1 3 0 2 3 1 1 3 4 0 1 2 3 0 0 1 1 2 2 3 1 4 0\n",
      " 2 0 0 3 3 0 3 1 0 1 0 4 3 0 3 1 2 1 3 1 0 2 4 0 1 1 4 0 4 0 2 0 2 3 1 4 3\n",
      " 3 3 2 3 4 0 4 2 2 0 3 2 1 4 3 2 3 0 1 0 3 1 3 1 4 1 2 4 3 2 4 1 4 4 4 2 4\n",
      " 4 0 3 0 2 1 2 1 4 4 1 3 3 0 4 0 0 2 2 0 1 1 0 4 3 2 2 4 2 4 0 3 1 4 4 3 4\n",
      " 3 2 4 1 3 3 4 4 2 0 2 1 1 2 1 0 3 0 2 4 4 0 2 4 1 1 2 3 4 2 2 1 2 2 1 3 2\n",
      " 0 2 3 2 3 0 2 0 4 4 2 3 1 0 0 0 1 0 4 1 3 1 0 4 1 3 3 1 0 1 2 0 2 4 4 3 0\n",
      " 4 4 2 4 0 0 0 4 2 0 1 3 1 0 2 0 4 3 4 3 3 2 2 1 4 1 1 2 1 1 0 2 1 2 0 0 1\n",
      " 3 3 0 4 0 1 3 2 1 3 2 0 2 4 0 0 2 1 4 2 2 4 1 2 0 1 1 3 2 2 4 4 1 4 4 1 3\n",
      " 4 4 3 2 0 0 4 4 0 3 3 4 3 3 3 4 1 0 0 2 3 3 2 0 2 3 3 2 4 3 2 2 0 4 2 1 2\n",
      " 0 2 4 4 0 0 1 1 2 1 2 2 4 3 0 0 3 0 2 2 1 3 0 1 2 1 0 2 2 4 0 1 1 1 3 2 2\n",
      " 2 0 0 2 2 4 0 3 0 1 1 4 3 3 0 3 0 2 2 4 1 0 4 4 1 2 3 4 3 0 2 0 4 3 4 3 0\n",
      " 1 2 4 1 1 3 0 0 0 1 1 4 1 3 3 2 1 1 0 3 0 4 1 2 1 1 2 1 0 2 1 4 3 4 3 1 2\n",
      " 1 3 2 0 4 4 3 4 2 1 3 0 2 3 0 3 3 2 2 4 4 3 3 2 1 2 3 0 1 2 3 2 3 0 3 4 0\n",
      " 4 3 0 1 1 4 2 2 3 2 3 1 3 4 3 0 1 3 0 4 1 0 3 1 0 0 4 1 0 1 4 3 2 3 1 0 2\n",
      " 0 1 2 4 1 3 2 1 0 3 4 0 3 3 1 1 2 1 2 2 0 3 1 1 1 2 0 1 4 1 4 0 2 1 1 0 3\n",
      " 0 3 4 3 0 1 2 0 3 0 4 0 2 0 4 2 0 2 3 4 2 2 0 1 0 0 2 4 0 0 4 2 4 3 2 4 3\n",
      " 3 4 0 0 0 0 2 1 1 3 3 2 1 4 2 0 4 1 4 3 4 3 1 4 3 4 3 1 4 4 1 0 3 0 2 1 2\n",
      " 1 3 4 0 3 3 2 4 1 2 3 0 2 2 0 3 4 3 2 0 3 2 3 2 3 0 1 1 4 1 4 2 0 1 0 1 1\n",
      " 1 1 3 3 1 0 3 2 1 2 3 2 3 0 1 1 3 0 4 1 1 4 0 1 1 2 3 0 0 4 0 3 0 3 1 0 1\n",
      " 2 2 4 2 1 0 1 0 2 0 0 4 4 1 3 2 1 0 3]\n"
     ]
    }
   ],
   "source": [
    "beesAns4 = mlp.predict(testData)\n",
    "print(beesAns4)\n",
    "writeResult('beesAns4', beesAns4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('commonMLalgs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "500cef33aa921c87c63c1753d003ac956bc931603b9c07a450ae237ef80e36a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
